import json
import time
import undetected_chromedriver as uc
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from webdriver_manager.chrome import ChromeDriverManager
from urllib.parse import urljoin


BASE_URL = "https://www.avito.ru/artem/zemelnye_uchastki/prodam"

def apply_filters(driver):
    """–ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä —Ü–µ–Ω—ã –¥–æ 1 200 000"""
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "input[data-marker='price-to/input']"))
        )

        max_price_input = driver.find_element(By.CSS_SELECTOR, "input[data-marker='price-to/input']")
        
        # –û—á–∏—â–∞–µ–º –ø–æ–ª–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é
        max_price_input.click()
        max_price_input.send_keys(Keys.CONTROL + "a")  # –í—ã–¥–µ–ª—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        max_price_input.send_keys(Keys.BACKSPACE)  # –£–¥–∞–ª—è–µ–º
        
        time.sleep(1)  # –ñ–¥–µ–º, —á—Ç–æ–±—ã –ø–æ–ª–µ –æ—á–∏—Å—Ç–∏–ª–æ—Å—å

        # –í–≤–æ–¥–∏–º —Ü–µ–Ω—É –ø–æ –æ–¥–Ω–æ–π —Ü–∏—Ñ—Ä–µ
        max_price = "1200000"
        for digit in max_price:
            max_price_input.send_keys(digit)
            time.sleep(0.2)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Ü–∏—Ñ—Ä—ã

        time.sleep(2)  # –î–∞–µ–º –≤—Ä–µ–º—è –ø–æ–ª—é –æ–±–Ω–æ–≤–∏—Ç—å—Å—è

        # –ù–∞–∂–∏–º–∞–µ–º –∫–Ω–æ–ø–∫—É "–ü–æ–∫–∞–∑–∞—Ç—å" –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        apply_button = driver.find_element(By.CSS_SELECTOR, "button[data-marker='search-filters/submit-button']")
        apply_button.click()

        # –ñ–¥–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div[data-marker='catalog-serp']"))
        )

        print("‚úÖ –§–∏–ª—å—Ç—Ä —Ü–µ–Ω—ã –ø—Ä–∏–º–µ–Ω–µ–Ω: –¥–æ 1 200 000 ‚ÇΩ")
        time.sleep(2)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–≤–æ–¥–µ —Ñ–∏–ª—å—Ç—Ä–∞ —Ü–µ–Ω—ã: {e}")

def get_all_listings():
    options = webdriver.ChromeOptions()
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-blink-features=AutomationControlled")

    driver = uc.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(BASE_URL)
    print("üåç –û—Ç–∫—Ä—ã—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞:", driver.current_url)

    apply_filters(driver)  # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
    current_url = driver.current_url  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π URL

    print("üîÑ –¢–µ–∫—É—â–∏–π URL –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞:", current_url)

    page = 1
    all_results = []
    global_index = 1  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π

    while True:
        paginated_url = f"{current_url}&p={page}"  # –¢–µ–ø–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        print(f"üìÑ –°–∫–∞–Ω–∏—Ä—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}: {paginated_url}")
        driver.get(paginated_url)

        # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div[data-marker='item']"))
            )
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
            break

        soup = BeautifulSoup(driver.page_source, "html.parser")
        listings = soup.find_all("div", {"data-marker": "item"})
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {len(listings)}")

        for item in listings:
            title_tag = item.find("a", {"data-marker": "item-title"})
            price_tag = item.find("p", {"data-marker": "item-price"})
            link_tag = item.find("a", {"data-marker": "item-title"})
            id_tag = item.get("data-item-id")  # –ü–æ–ª—É—á–∞–µ–º ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è

            title_text = title_tag.text.strip() if title_tag else "–ù–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞"
            price_value = price_tag.find("meta", {"itemprop": "price"})["content"] if price_tag else "–ù–µ—Ç —Ü–µ–Ω—ã"
            price_text = price_tag.find("span").text.strip() if price_tag and price_tag.find("span") else "–ù–µ—Ç —Ü–µ–Ω—ã"
            link_href = urljoin("https://www.avito.ru", link_tag["href"]) if link_tag else "–ù–µ—Ç —Å—Å—ã–ª–∫–∏"
            item_id = id_tag if id_tag else "–ù–µ—Ç ID"

            all_results.append({
                "order": global_index,
                "id": item_id,
                "title": title_text,
                "price": price_value,
                "formatted_price": price_text,
                "link": link_href
            })

            global_index += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–Ω–æ–ø–∫—É "–°–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"
        next_button = soup.find("a", {"data-marker": "pagination-button/nextPage"})
        if next_button:
            page += 1
            time.sleep(3)  # –£–º–µ–Ω—å—à–∏–ª–∏ –∑–∞–¥–µ—Ä–∂–∫—É
        else:
            print("üèÅ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞.")
            break

    driver.quit()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
    with open("all_results.json", "w", encoding="utf-8") as file:
        json.dump(all_results, file, indent=4, ensure_ascii=False)

    print(f"üìÇ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ all_results.json ({len(all_results)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π)")


def main():
    get_all_listings()


if __name__ == "__main__":
    main()